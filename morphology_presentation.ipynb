{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology and Python\n",
    "\n",
    "Me:\n",
    "- Steven Butler\n",
    "- srbutler at gmail dot com\n",
    "\n",
    "Important links:\n",
    "\n",
    "- Morpho Project: http://www.cis.hut.fi/projects/morpho/\n",
    "- ReadtheDocs: http://morfessor.readthedocs.io/en/latest/index.html\n",
    "- Github: https://github.com/aalto-speech/morfessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfessor Demonstration\n",
    "This is a demo of the Morfessor library using sample files from Morpho Challenge 2005. To run the code below, you'll need to download some data files from the following link and save them in a folder called \"data/\".\n",
    "\n",
    "http://research.ics.aalto.fi/events/morphochallenge2005/datasets.shtml\n",
    "\n",
    "Note that these scripts should run on both CPython and PyPy. I use PyPy most of the time when I can, as it can speed things up by nearly an order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import morfessor\n",
    "\n",
    "## logging makes the output a lot more useful\n",
    "## though apparently it only shows up in a console, not in notebooks\n",
    "_logger = logging.getLogger(__name__)\n",
    "default_formatter = logging.Formatter('%(asctime)s - %(message)s', '%Y-%m-%d %H:%M:%S')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "main_logger = logging.StreamHandler()\n",
    "main_logger.setLevel(logging.INFO)\n",
    "main_logger.setFormatter(default_formatter)\n",
    "_logger.addHandler(main_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Morfessor\n",
    "\n",
    "This function shows the basic setup to train a Morfessor model. It is *highly* recommended that you save the model to a .pickle file, as retraining every time will take up a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(input_file, output_file=None):\n",
    "\n",
    "    ## setup input and model objects\n",
    "    morf_io = morfessor.MorfessorIO()\n",
    "    morf_model = morfessor.BaselineModel()\n",
    "\n",
    "    ## build a corpus from input file\n",
    "    train_data = morf_io.read_corpus_file(input_file)\n",
    "\n",
    "    ## load data into model\n",
    "    ## optional param \"count_modifier\" can set frequency dampening;\n",
    "    ## default is each token counts\n",
    "    morf_model.load_data(train_data)\n",
    "\n",
    "    ## train the model in batch form (online training also available)\n",
    "    morf_model.train_batch()\n",
    "\n",
    "    ## optionally pickle model\n",
    "    if output_file is not None:\n",
    "        morf_io.write_binary_model_file(output_file, morf_model)\n",
    "\n",
    "    return morf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## train a model on the Turkish dataset and save it to a file\n",
    "## be patient! it will be slow.\n",
    "# model_turkish = train_model(\"data/wordlist.tur\", \"output/trainedmodel.tur\")\n",
    "# model_english = train_model(\"data/wordlist.eng\", \"output/trainedmodel.eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## otherwise, use the trained model if it's already saved\n",
    "morf_io = morfessor.MorfessorIO()\n",
    "\n",
    "model_turkish = morf_io.read_binary_model_file(\"output/trainedmodel.tur\")\n",
    "model_english = morf_io.read_binary_model_file(\"output/trainedmodel.eng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting with Morfessor\n",
    "\n",
    "A trained model can be used to segment a list of words. If you trust the model for your corpus (i.e., you've seen gold standard tested results in another paper), this might be your last step.\n",
    "\n",
    "The output from the segmenter is a list of segments and the log probability that this is the correct segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['bilincin', 'le'], 19.89222449520654)\n",
      "(['eyleme', 'lerine'], 20.86651055320383)\n",
      "(['komedi', 'dir'], 19.75392446733094)\n",
      "(['uygar', 'laStI', 'ramadIklarI', 'mIzdan', 'mIS', 'sInIz', 'casIna'], 72.7934925399708)\n"
     ]
    }
   ],
   "source": [
    "## segment data using the trained Turkish model\n",
    "\n",
    "words_turkish = [\"bilincinle\", \"eylemelerine\", \"komedidir\", \"uygarlaStIramadIklarImIzdanmISsInIzcasIna\"]\n",
    "\n",
    "for word in words_turkish:\n",
    "    print(model_turkish.viterbi_segment(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['un', 'believable'], 19.32113757371785)\n",
      "(['present', 'ed'], 16.555310976357404)\n",
      "(['quick', 'ly'], 17.118524084472)\n",
      "(['morpholog', 'y'], 18.430928507097743)\n",
      "(['morpholog', 'ical'], 21.07542358801313)\n",
      "(['unde', 'compos', 'able'], 29.499639370389204)\n",
      "(['the'], 9.775824751238426)\n"
     ]
    }
   ],
   "source": [
    "## segment data using the trained English model\n",
    "\n",
    "words_english = [\"unbelievable\", \"presented\", \"quickly\", \"morphology\", \"morphological\", \"undecomposable\", \"the\"]\n",
    "\n",
    "for word in words_english:\n",
    "    print(model_english.viterbi_segment(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation with Morfessor\n",
    "\n",
    "A *gold standard* segmentation file is needed to assess the quality of the model. It will provide precision, recall, and F-measure scores for a given trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# need to set sample sizes\n",
    "from morfessor.evaluation import EvaluationConfig\n",
    "\n",
    "# 10 samples of 50 words\n",
    "eval_config = EvaluationConfig(10, 50)\n",
    "\n",
    "# get the data from the annotations files\n",
    "morf_io = morfessor.MorfessorIO()\n",
    "goldstd_turkish = morf_io.read_annotations_file(\"data/goldstdsample.tur.txt\")\n",
    "goldstd_english = morf_io.read_annotations_file(\"data/goldstdsample.eng.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename   : UNKNOWN\n",
      "Num samples: 10\n",
      "Sample size: 50.0\n",
      "F-score    : 0.577\n",
      "Precision  : 0.777\n",
      "Recall     : 0.461\n"
     ]
    }
   ],
   "source": [
    "# build evaluator object and run evaluation against Turkish gold standard\n",
    "evaluator_turkish = morfessor.MorfessorEvaluation(goldstd_turkish)\n",
    "results_turkish = evaluator_turkish.evaluate_model(model_turkish, configuration=eval_config)\n",
    "print(results_turkish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename   : UNKNOWN\n",
      "Num samples: 10\n",
      "Sample size: 50.0\n",
      "F-score    : 0.7\n",
      "Precision  : 0.714\n",
      "Recall     : 0.69\n"
     ]
    }
   ],
   "source": [
    "# build evaluator object and run evaluation against English gold standard\n",
    "evaluator_english = morfessor.MorfessorEvaluation(goldstd_english)\n",
    "results_english = evaluator_english.evaluate_model(model_english, configuration=eval_config)\n",
    "print(results_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Infixer Demonstration\n",
    "\n",
    "This process targets language patterns that involve **non-concatenative** morphology, which Morfessor is not terribly good at. The basic idea is: supervise the Morfessor algorithm with regular expressions. The data that have the targeted patterns will be **linearized** by rebuilding the *non-concatenative* patterns into *concatenative* ones.\n",
    "\n",
    "The needed files should be saved in the same directory--I haven't built them into a library yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from model import InfixerModel\n",
    "from eval_segment import InfixerSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affix_list = [r'^(?P<CON>\\w)(in)(?P<VOW>\\w)((?P=CON)(?P=VOW)\\w*)',\n",
    "              r'^(?P<CON>\\w)(um)(?P<VOW>\\w)((?P=CON)(?P=VOW)\\w*)',\n",
    "              r'^(i?\\w)(in)(\\w+)',\n",
    "              r'^(i?\\w)(um)(\\w+)',\n",
    "              r'^(?P<REDUP>\\w+)((?P=REDUP)\\w+)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get stored model and feature dict\n",
    "infixer_io = morfessor.MorfessorIO()\n",
    "model_tagalog = infixer_io.read_binary_model_file(\"output/tl_wiki_rdi_none_bin\")\n",
    "features_tagalog = InfixerModel.get_feature_dict_from_file(\"output/tl_wiki_rdi_none.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basa: basa\n",
      "bumasa: <um> basa\n",
      "bumabasa: <redup> <um> basa\n",
      "binasa: <in> basa\n",
      "binabasa: <redup> <in> basa\n",
      "babasahin: <redup> basa hin\n"
     ]
    }
   ],
   "source": [
    "# set up a segmenter\n",
    "segmenter_tagalog = InfixerSegmenter(model_tagalog, features_tagalog, affix_list)\n",
    "\n",
    "words_tagalog = [\"basa\", \"bumasa\", \"bumabasa\", \"binasa\", \"binabasa\", \"babasahin\"]\n",
    "\n",
    "segmentations_tagalog = segmenter_tagalog.segment_list(words_tagalog)\n",
    "\n",
    "for (word, segmentation) in segmentations_tagalog:\n",
    "    print(word+\":\", segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
